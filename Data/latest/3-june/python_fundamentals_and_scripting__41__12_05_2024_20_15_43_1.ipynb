{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e2b6342",
      "metadata": {
        "id": "9e2b6342"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**Topic** - python fundamentals and scripting\n",
        "\n",
        "**Target Number of Turns (User + Assistant) - 2**\n",
        "\n",
        "**Suggested Conversation :** - How can a developer refactor a traditional for-loop that performs API calls into an asynchronous loop using asyncio to improve the performance of a data aggregation script?\n",
        "\n",
        "**User Personality :** - Analytical, patient, and collaborative. Prefers to meticulously assess the performance implications of synchronous code and is willing to spend time understanding the asyncio library. Enjoys working with others to find the most efficient solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08c5e03d",
      "metadata": {
        "id": "08c5e03d"
      },
      "source": [
        "# Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aedeb88c",
      "metadata": {
        "id": "aedeb88c"
      },
      "source": [
        "**User**\n",
        "\n",
        "How can I refactor a traditional for-loop that performs API calls into an asynchronous loop using asyncio to improve the performance of a data aggregation script?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Sure! Let's construct an example utilizing a fictitious situation in which we must simultaneously retrieve data from several endpoints. The `aiohttp` library will be used to make asynchronous HTTP queries. Before executing the code, make sure you use `pip install aiohttp` to install `aiohttp`."
      ],
      "metadata": {
        "id": "0aGSsgLBCcC_"
      },
      "id": "0aGSsgLBCcC_"
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "\n",
        "async def fetch_data(session, url):\n",
        "    async with session.get(url) as response:\n",
        "        data = await response.json()\n",
        "        return data\n",
        "\n",
        "async def fetch_all_data(urls):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [fetch_data(session, url) for url in urls]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "        return results\n",
        "\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://jsonplaceholder.typicode.com/posts/1\",\n",
        "        \"https://jsonplaceholder.typicode.com/posts/2\",\n",
        "        \"https://jsonplaceholder.typicode.com/posts/3\",\n",
        "        # Add more URLs as needed\n",
        "    ]\n",
        "\n",
        "    data = await fetch_all_data(urls)\n",
        "    for i, result in enumerate(data):\n",
        "        print(f\"Data from URL {i+1}: {result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DxcqD_jCcwM",
        "outputId": "9bc9ecb6-19de-4fa1-de2e-58ef0d685128"
      },
      "id": "_DxcqD_jCcwM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from URL 1: {'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n",
            "Data from URL 2: {'userId': 1, 'id': 2, 'title': 'qui est esse', 'body': 'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla'}\n",
            "Data from URL 3: {'userId': 1, 'id': 3, 'title': 'ea molestias quasi exercitationem repellat qui ipsa sit aut', 'body': 'et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this solution, we implement the following improvements:\n",
        "\n",
        "- We define an `async` function `fetch_data` that takes a session object and a URL. Inside this function, we make an asynchronous HTTP GET request to the given URL using `session.get()`. We then await the response and parse it as JSON.\n",
        "- Another `async` function `fetch_all_data` takes a list of URLs. It creates a session using `aiohttp.ClientSession()`, creates a list of coroutines for fetching data from each URL using `fetch_data`, and then awaits all these coroutines using `asyncio.gather()`.\n",
        "- In the `main` function, we define our list of URLs and await the results of fetching data from all URLs concurrently. Finally, we print the fetched data.\n",
        "\n",
        "This example demonstrates how to fetch data from multiple URLs concurrently using `asyncio` and `aiohttp`, significantly improving the performance of your data aggregation script compared to sequential fetching."
      ],
      "metadata": {
        "id": "2dtV5uYZCfBx"
      },
      "id": "2dtV5uYZCfBx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User**\n",
        "\n",
        "How can I optimize a script that makes API calls in a for-loop by leveraging asyncio for concurrent execution?"
      ],
      "metadata": {
        "id": "oL2Nh10PCfvc"
      },
      "id": "oL2Nh10PCfvc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Sure, lets improve the previous code to incorporate asyncio for concurrent execution of API calls. Here's the revised version:"
      ],
      "metadata": {
        "id": "VCMMiqrwCirW"
      },
      "id": "VCMMiqrwCirW"
    },
    {
      "cell_type": "code",
      "source": [
        "  import asyncio\n",
        "  import aiohttp\n",
        "\n",
        "  async def fetch_data(session, url):\n",
        "      async with session.get(url) as response:\n",
        "          data = await response.json()\n",
        "          return data\n",
        "\n",
        "  async def fetch_all_data(urls):\n",
        "      async with aiohttp.ClientSession() as session:\n",
        "          tasks = [fetch_data(session, url) for url in urls]\n",
        "          results = await asyncio.gather(*tasks)\n",
        "          return results\n",
        "\n",
        "  async def main():\n",
        "      urls = [\n",
        "          \"https://jsonplaceholder.typicode.com/posts/1\",\n",
        "          \"https://jsonplaceholder.typicode.com/posts/2\",\n",
        "          \"https://jsonplaceholder.typicode.com/posts/3\",\n",
        "          # Add more URLs as needed\n",
        "      ]\n",
        "\n",
        "      data = await fetch_all_data(urls)\n",
        "      for i, result in enumerate(data):\n",
        "          print(f\"Data from URL {i+1}: {result}\")\n",
        "\n",
        "  if __name__ == \"__main__\":\n",
        "      await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcSOVLysChQT",
        "outputId": "325571a6-707d-4073-f6f2-dedf58a316d6"
      },
      "id": "RcSOVLysChQT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from URL 1: {'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n",
            "Data from URL 2: {'userId': 1, 'id': 2, 'title': 'qui est esse', 'body': 'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla'}\n",
            "Data from URL 3: {'userId': 1, 'id': 3, 'title': 'ea molestias quasi exercitationem repellat qui ipsa sit aut', 'body': 'et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this new version, we add these new improvements:\n",
        "\n",
        "- We use the `aiohttp` library to make asynchronous HTTP requests.\n",
        "- The `fetch_data` function now takes a session object and a URL as parameters. It makes an asynchronous GET request to the URL using the session and awaits the response, parsing it as JSON.\n",
        "- The `fetch_all_data` function creates a session using `aiohttp.ClientSession()`, creates a list of coroutines for fetching data from each URL using `fetch_data`, and awaits all these coroutines using `asyncio.gather()`.\n",
        "- In the `main` function, we define our list of URLs and await the results of fetching data from all URLs concurrently. Finally, we print the fetched data."
      ],
      "metadata": {
        "id": "fbOqIQzQClRK"
      },
      "id": "fbOqIQzQClRK"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}