{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2d474c2",
      "metadata": {
        "id": "a2d474c2"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**Topic** - algorithm problems using python\n",
        "\n",
        "**Target Number of Turns (User + Assistant) - 3**\n",
        "\n",
        "**Suggested Conversation :** - How can a Python developer implement a parallel merge sort algorithm using the multiprocessing module to sort a large dataset, and what considerations should be taken into account regarding data partitioning and process synchronization?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4767f1",
      "metadata": {
        "id": "be4767f1"
      },
      "source": [
        "# Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0453efe",
      "metadata": {
        "id": "c0453efe"
      },
      "source": [
        "**User**\n",
        "\n",
        "I need to sort a large dataset. Implement a parallel merge sort in Python using multiprocessing and explain what considerations should be taken into account regarding data partitioning and process synchronization."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "A parallel merge sort can be implemented following these steps:\n",
        "1. define the number of processes to use. Usually, this number is the same as the CPU core count of the system\n",
        "2. split the data into *n* chunks, where *n* is the number of processes.\n",
        "3. allocate each chunk to a process for sorting\n",
        "4. merge the sorted results\n",
        "\n",
        "\n",
        "Here is how it can be implemented:"
      ],
      "metadata": {
        "id": "kT2ZxYXFZVk7"
      },
      "id": "kT2ZxYXFZVk7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistant\n",
        "\n",
        "import math\n",
        "import multiprocessing\n",
        "\n",
        "\n",
        "def parallel_merge_sort(input, processes):\n",
        "    print(f\"Sorting {len(input)} in parallel with {processes} processes\")\n",
        "    # Divide the input array into n chunks\n",
        "    chunk_size = math.ceil(len(input) / processes)\n",
        "    chunks = [input[chunk_size * i : chunk_size * (i + 1)] for i in range(processes)]\n",
        "\n",
        "    # Create a process pool and map each chunk to be sorted\n",
        "    pool = multiprocessing.Pool(processes)\n",
        "    with pool:\n",
        "        mapping = pool.map(merge_sort_exception_handler, chunks)\n",
        "\n",
        "    if any(part is None for part in mapping):\n",
        "        raise Exception(\"Error while sorting\")\n",
        "\n",
        "    # Then merge the sorted arrays\n",
        "    return merge_results(mapping)\n",
        "\n",
        "\n",
        "def merge_sort_exception_handler(input):\n",
        "    try:\n",
        "        return merge_sort(input)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# A simple merge sort\n",
        "def merge_sort(input):\n",
        "    if len(input) <= 1:\n",
        "        return input\n",
        "\n",
        "    mid = len(input) // 2\n",
        "    left_half = input[:mid]\n",
        "    right_half = input[mid:]\n",
        "    return merge(merge_sort(left_half), merge_sort(right_half))\n",
        "\n",
        "\n",
        "# Almost the same as merge sort, but its only task is to join the results\n",
        "def merge_results(arrays):\n",
        "    if len(arrays) == 1:\n",
        "        return arrays[0]\n",
        "\n",
        "    mid = len(arrays) // 2\n",
        "    left_half = arrays[:mid]\n",
        "    right_half = arrays[mid:]\n",
        "\n",
        "    # Here we can use the same merge function as merge_sort\n",
        "    return merge(merge_results(left_half), merge_results(right_half))\n",
        "\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] < right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    result += left[i:]\n",
        "    result += right[j:]\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Don't forget to put this inside the __main__ condition\n",
        "if __name__ == \"__main__\":\n",
        "    elements = 100_000\n",
        "    input_array = random.sample(range(elements), elements)\n",
        "    print(parallel_merge_sort(input=input_array, processes=os.cpu_count() or 1))"
      ],
      "metadata": {
        "id": "W0IYeKxyYpJv"
      },
      "id": "W0IYeKxyYpJv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "\n",
        "Here's a brief explanation of `parallel_merge_sort` and why data partitioning and process synchronization are crucial:\n",
        "\n",
        "1. **Data Partitioning:** Initially, the input array is evenly divided among the available processes, with each process receiving a portion of the data, known as a chunk. This partitioning is fundamental to parallel processing efficiency. Equal distribution of data ensures that all processes have an approximately equal workload, which prevents scenarios where some processors are idle waiting for others to complete. An even partitioning optimizes resource utilization and contributes to a more uniform processing time across the board.\n",
        "\n",
        "2. **Independent Sorting:** Each process then independently sorts its assigned chunk using the merge sort algorithm. This step exemplifies the essence of parallel computation, where multiple sub-tasks (in this case, sorting smaller arrays) are executed concurrently. Since these operations are independent, there's no need for synchronization during this phase, which minimizes the complexity and overhead usually associated with concurrent modifications to shared data.\n",
        "\n",
        "3. **Synchronization and Merging:** After all processes have completed their sorting tasks, the main program synchronizes these processes to ensure all sorting is finished before proceeding. This synchronization is crucial as it marks the transition from independent parallel operations to a sequential merging phase. The sorted chunks are then merged by the main program, not in parallel but rather sequentially, in a single process. This merging process itself involves sorting as it combines the chunks, ensuring the final array is sorted correctly.\n",
        "\n",
        "**Important Considerations:**\n",
        "\n",
        "- **Even Data Distribution:** As mentioned, ensuring that data is evenly distributed among the processes is crucial for achieving optimal performance. An imbalance in the distribution can cause some processes to be overburdened while others sit idle, leading to suboptimal utilization of computational resources.\n",
        "\n",
        "- **Handling Race Conditions:** In parallel computing, race conditions can occur when multiple processes attempt to read, write, or change shared data simultaneously. Proper synchronization mechanisms must be in place to prevent these issues, ensuring data integrity and correctness of the final sorted array.\n",
        "\n",
        "- **Overhead Management:** The benefits of parallel processing come with the cost of additional overhead for process management. This includes the time and resources needed to start processes, divide the data, and merge the sorted chunks. For smaller datasets, the overhead may outweigh the benefits, making a single-threaded approach more efficient.\n",
        "\n",
        "- **Memory Usage:** Parallel merge sort can also increase the total memory footprint, as data needs to be duplicated across processes. This can impact performance, especially on systems with limited memory resources.\n",
        "\n",
        "\n",
        "Note: If you are running everything from a single file, do not forget to put the element initialization and the call to `parallel_merge_sort` inside the `if __name__ == \"__main__\"` condition; otherwise, it will be run every time the multiprocessing module spawns a new instance to run the sorting function."
      ],
      "metadata": {
        "id": "DijWT2V1cd1U"
      },
      "id": "DijWT2V1cd1U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User**\n",
        "\n",
        "Why is a single-threaded approach better for smaller sequences?"
      ],
      "metadata": {
        "id": "Y6Vr7SYedhnq"
      },
      "id": "Y6Vr7SYedhnq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "For smaller sequences, a single-threaded approach could be more efficient because the overhead of managing multiple processes may outweigh the benefits of parallelization. This overhead includes creating, coordinating, and communicating between processes. When the sequence is large, the benefits of parallelized computing (faster processing due to simultaneous execution) can outpace this overhead, thus making parallel sorting a more effective option.\n",
        "\n",
        "Still, the given code for sorting and merging data might not meet the performance expectations for handling large datasets in practical applications. These code snippets are primarily used to demonstrate the concept and should be substituted with more efficient techniques when dealing with high-performance demands."
      ],
      "metadata": {
        "id": "RS7TngfQdvXn"
      },
      "id": "RS7TngfQdvXn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User**\n",
        "\n",
        "And what techniques could I use when dealing with high-performance demands?"
      ],
      "metadata": {
        "id": "NrJBtTbVfTuF"
      },
      "id": "NrJBtTbVfTuF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "If you're searching for optimal efficiency, it may be best to leverage a lower-level language like C/C++, Rust, or Go. However, if your project necessitates the use of Python, you have a few alternatives at your disposal:\n",
        "\n",
        "1. Implement a high-performance framework such as Numba, which has the ability to compile your functions just-in-time (JIT) and can even execute them on CUDA cores.\n",
        "2. Venturing into using a different Python interpreter, such as PyPy.\n",
        "3. Opt for a language similar to Python, like Cython."
      ],
      "metadata": {
        "id": "Atv_qSPFfcmk"
      },
      "id": "Atv_qSPFfcmk"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}