{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "986e4720",
      "metadata": {
        "id": "986e4720"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**Topic** - algorithm problems using python\n",
        "\n",
        "**Target Number of Turns (User + Assistant) - 1**\n",
        "\n",
        "**Suggested Conversation :** - How can one implement Principal Component Analysis (PCA) from scratch in Python to reduce the dimensionality of a dataset, ensuring that the resulting components retain the maximum possible variance from the original features? Provide a code example that includes data standardization, computation of the covariance matrix, eigenvalue decomposition, and projection of the original dataset onto the new feature space."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33636f88",
      "metadata": {
        "id": "33636f88"
      },
      "source": [
        "# Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e76d1c",
      "metadata": {
        "id": "a2e76d1c"
      },
      "source": [
        "**User**\n",
        "\n",
        "Implement PCA (Principal Component Analysis) from scratch in Python to reduce the dimensionality of a given dataset retaining the maximum possible variance from the original features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Certainly! PCA (Principal Component Analysis) is a statistical procedure for dimensionality reduction often used to reduce the dimensionality of large datasets. Implementing PCA from scratch in Python involves several steps: Data Standardization, computation of covariance matrix, eigenvalue decomposition, and projection of the original dataset onto the new feature space. Here is a step-by-step guide with a code example."
      ],
      "metadata": {
        "id": "6l3K7WvkdaFh"
      },
      "id": "6l3K7WvkdaFh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistant\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def principal_component_analysis(X, num_components, standardize=True):\n",
        "    try:\n",
        "        # Input validation\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            raise TypeError(\"Input data must be a numpy.ndarray!\")\n",
        "        if len(X.shape) != 2:\n",
        "            raise ValueError(\"Input data must be a 2D array!\")\n",
        "        if not isinstance(num_components, int):\n",
        "            raise TypeError(\"Number of components must be an integer!\")\n",
        "        if num_components <= 0:\n",
        "            raise ValueError(\"Number of components must be greater than 0!\")\n",
        "        if num_components > X.shape[1]:\n",
        "            raise ValueError(\"Number of components must be less than or equal to number of features!\")\n",
        "\n",
        "        # Standardizing the dataset (optional) and always centering\n",
        "        mean = np.mean(X, axis=0)\n",
        "        if standardize:\n",
        "            std_dev = np.std(X, axis=0, ddof=1)\n",
        "            X = (X - mean) / std_dev\n",
        "        else:\n",
        "            X = X - mean\n",
        "\n",
        "        # Calculate the covariance matrix\n",
        "        covariance_matrix = np.cov(X, rowvar=False) # rowvar=False means that columns represent variables\n",
        "\n",
        "\n",
        "        # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "        if np.iscomplexobj(eigenvalues):\n",
        "            raise ValueError(\"Complex eigenvalues encountered. PCA might not be suitable for this dataset!\")\n",
        "\n",
        "        # Sort eigenvectors by their associated eigenvalues in descending order\n",
        "        idx = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvalues = eigenvalues[idx]\n",
        "        # Align eigenvectors with sorted eigenvalues\n",
        "        eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "        # Select the first num_components eigenvectors\n",
        "        eigenvectors = eigenvectors[:, :num_components]\n",
        "\n",
        "        # Transform the original matrix by projecting data onto principal components\n",
        "        X_pca = np.dot(X, eigenvectors)\n",
        "\n",
        "        total_variance = np.sum(eigenvalues)\n",
        "        explained_variance = eigenvalues[:num_components] / total_variance\n",
        "\n",
        "        return X_pca, explained_variance\n",
        "\n",
        "    except TypeError as te:\n",
        "        print(f\"TypeError: {te}\")\n",
        "        return None\n",
        "    except ValueError as ve:\n",
        "        print(f\"ValueError: {ve}\")\n",
        "        return None\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    X = np.random.randn(500, 6)  # Simulated data\n",
        "\n",
        "    # Specify the number of components\n",
        "    num_components = 2\n",
        "\n",
        "    # Perform PCA with standardization and get the transformed data and variance explained\n",
        "    transformed_data, explained_variance = principal_component_analysis(X, num_components, standardize=True)\n",
        "\n",
        "    if transformed_data is not None and explained_variance is not None:\n",
        "        print(\"Original data shape: \", X.shape)\n",
        "        print(\"Transformed data shape: \", transformed_data.shape)\n",
        "        print(\"Variance explained by each principal component: \", explained_variance)\n",
        "    else:\n",
        "        print(\"PCA computation failed.\")"
      ],
      "metadata": {
        "id": "n_8TPqU-dZd9"
      },
      "id": "n_8TPqU-dZd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "In this code, We follow these steps to achieve PCA:\n",
        "\n",
        "\n",
        "* **Input Checks:** Validate the input data type, ensure the input is a **`2D numpy array`**, verify the number of features, and validate that the desired number of components is a positive integer less than or equal to the number of features in the dataset.\n",
        "\n",
        "* **(Optional): Standardize Data:** If the **`standardize`** parameter is set to **`True`**, the function calculates the mean and standard deviation of each feature to normalize the data by subtracting the mean and dividing by the standard deviation. If **`False`**, this step is skipped.\n",
        "\n",
        "* **Compute Covariance Matrix:** Calculate the **`covariance matrix`** using the (potentially standardized) data.\n",
        "\n",
        "* **Eigen Decomposition and Error Handling:** Perform an eigen-decomposition on the covariance matrix to obtain `eigenvalues` and `eigenvectors`. If complex eigenvalues are encountered, raise a ValueError as PCA may not be suitable for this dataset.\n",
        "\n",
        "* **Sort Eigen Pairs:** The function sorts the eigenvectors in decreasing order based on their associated eigenvalues\n",
        "\n",
        "* **Select Principal Components:** It selects the top **`'num_components'`** eigenvectors (principal components) based on their associated sorted eigenvalues.\n",
        "\n",
        "* **Project Data:** The function transforms the original data onto the subspace spanned by the chosen principal components.\n",
        "\n",
        "* **Variance Explained:** Calculate the proportion of total variance explained by each selected principal component.\n",
        "\n",
        "* **Error Handling:** If **`TypeError`** or **`ValueError`** exceptions occur during any of these steps, they will be caught and an error message will be printed, indicating the problem. The function will return **`None, None`** in this case.\n",
        "\n",
        "The **`num_components`** parameter can be adjusted according to the desired number of principal components to be retained, as long as it is not greater than the number of features in the dataset. Similarly, the **`standardize`** parameter can be toggled depending on whether standardization is desired or not."
      ],
      "metadata": {
        "id": "dmSmHzU58pGq"
      },
      "id": "dmSmHzU58pGq"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}