{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"User is not allowed to create run. UserProjectRole with User Email 'daniel.oluwakayode-c@turing.com', Engagement Name 'public-engagement' and Project Name 'beta-test' not found\"}\n",
      "Authentication failed.\n"
     ]
    }
   ],
   "source": [
    "from Agents.utils import split_notebook_turns\n",
    "from Agents.agents import turn_classifier\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_turns = split_notebook_turns(\"Data/python_basics_&_scripting__write_code_in_python__22__24_03_2024_08_57_45_10.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'User',\n",
       "  'content': \"Right now, the code doesn't explicitly verify if the write operation was successful. Are there ways to check if the new name was written correctly to the file?\"},\n",
       " {'role': 'Assistant',\n",
       "  'content': \"You're absolutely right, verifying the write operation's success is crucial for ensuring data integrity. Here are two ways to check if the new name was written correctly to the file in the provided Python script:\\n\\n1. `Using file.tell()`:\\n\\n* After writing the new name data using `file.write()`, you can call `file.tell()`. This method returns the current position of the file pointer.\"},\n",
       " {'role': 'Assistant',\n",
       "  'content': '# After writing the new name...\\nnew_name_end_position = file.tell()\\n\\n# Compare the written bytes with the expected size of the new name data\\nexpected_bytes_written = len(new_name_encoded)\\nif new_name_end_position - byte_offset == expected_bytes_written:\\n    print(\"Employee record updated successfully!\")\\nelse:\\n    print(\\n        \"Error: An unexpected number of bytes were written. Update might be incomplete.\"\\n    )'},\n",
       " {'role': 'Assistant',\n",
       "  'content': 'This approach compares the difference between the file pointer position after writing (`new_name_end_position`) and the initial byte offset (`byte_offset`) with the expected number of bytes written (`expected_bytes_written`). If they match, it indicates a successful write operation.\\n\\n2. **Reading Back the Updated Data (Optional)**:\\n\\n* You can optionally read the updated data back from the file after writing the new name. This involves seeking back to the beginning of the name field within the record and reading the data of the same size as the new name.'},\n",
       " {'role': 'Assistant',\n",
       "  'content': '# After writing the new name...\\nfile.seek(byte_offset + 4)  # Seek back to the beginning of the name field\\n\\nupdated_name_data = file.read(20)  # Read 20 bytes for the name field\\n\\n# Compare the read data with the encoded new name\\nif updated_name_data == new_name_encoded:\\n    print(\"Employee record updated successfully!\")\\nelse:\\n    print(\"Error: Data mismatch after write. Update might be incorrect.\")'},\n",
       " {'role': 'Assistant',\n",
       "  'content': 'This approach verifies if the written data actually matches the intended new name by reading it back and comparing it with the encoded new name.\\n\\n**Choosing the Approach**:\\n\\n* The first approach (`file.tell()`) is simpler and avoids additional reads.\\n* The second approach (`reading back`) offers a more robust verification but requires additional file operations.\\n\\nSelect the approach that best suits your needs based on the desired level of verification and potential performance considerations. Remember to modify the byte offsets and data sizes based on your specific data structure.\\n\\nHope that gives you the answer. If you require further clarification, feel free to reach out to me.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_turns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating output schema.....\n",
      "{'has_code': False, 'complete_code': False, 'can_be_tested': False, 'code': '', 'dependencies': [], 'language': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = conversation_turns[0]\n",
    "result = turn_classifier([HumanMessage(\"hello how are you?\")])\n",
    "print(result)\n",
    "all([result[\"has_code\"], result[\"complete_code\"], result[\"can_be_tested\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating output schema.....\n",
      "{'has_code': True, 'complete_code': False, 'can_be_tested': False, 'code': \"print('i am fine)\", 'dependencies': [], 'language': 'python3'}\n"
     ]
    }
   ],
   "source": [
    "result = turn_classifier([HumanMessage(\"print('i am fine)\")])\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
