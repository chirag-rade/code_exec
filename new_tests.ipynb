{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"User is not allowed to create run. UserProjectRole with User Email 'daniel.oluwakayode-c@turing.com', Engagement Name 'public-engagement' and Project Name 'beta-test' not found\"}\n",
      "Authentication failed.\n"
     ]
    }
   ],
   "source": [
    "from Agents.utils import split_notebook_turns\n",
    "from Agents.agents import turn_classifier\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_turns = split_notebook_turns(\"Data/python_basics_&_scripting__write_code_in_python__22__24_03_2024_08_57_45_10.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'Assistant',\n",
       "  'content': \"Sure, I can help you with that. Here's how you can implement seek and write operations to modify a specific record in a binary file containing employee data in Python:\\n\\n**Approaches**:\\n\\n1. **Calculate Byte Offset**: Determine the starting byte position of the target record based on the record size and record number.\\n\\n2. **Open File in 'rb+ mode**: Open the binary file in read-write binary mode (`'rb+'`). This allows both reading and modifying the file contents.\\n\\n3. **Seek to Record Position**: Use the `file.seek()` method to move the file pointer to the calculated byte offset of the target record.\\n\\n4. **Read Existing ID (Optional)**: You can optionally read the existing ID at this position for verification purposes using `file.read(size)`.\\n\\n5. **Encode New Name**: Encode the new name string with the same fixed length as the original name field (truncate or pad with spaces).\\n\\n6. **Write New Name**: Use `file.write()` to write the encoded new name data at the current file pointer position, effectively overwriting the existing name in the record.\\n\\nCode Example:\"},\n",
       " {'role': 'Assistant',\n",
       "  'content': 'def update_employee_name(filename, record_number, new_name):\\n  \"\"\"\\n  Updates the name field for a specific record in a binary employee data file.\\n\\n  Args:\\n      filename (str): Path to the binary file.\\n      record_number (int): The index of the record to update (0-based).\\n      new_name (str): The new name to write to the file.\\n  \"\"\"\\n\\n  # Define employee record size (assuming integer id and fixed-length name)\\n  record_size = 4 + 20  # 4 bytes for integer id, 20 bytes for fixed-length name\\n\\n  try:\\n    with open(filename, \\'rb+\\') as file:\\n      # Calculate byte offset for the record\\n      byte_offset = record_number * record_size\\n\\n      # Seek to the record position\\n      file.seek(byte_offset)\\n\\n      # Read the existing id (optional, for verification)\\n      id_data = file.read(4)\\n      id = int.from_bytes(id_data, byteorder=\\'little\\')\\n\\n      # Encode the new name with fixed length (truncate or pad with spaces)\\n      new_name_encoded = new_name[:20].encode() + b\\' \\' * (20 - len(new_name))\\n\\n      # Write the updated name data\\n      file.write(new_name_encoded)\\n\\n      print(f\"Employee record #{record_number} (ID: {id}) name updated successfully!\")\\n\\n  except FileNotFoundError:\\n    print(f\"Error: File \\'{filename}\\' not found.\")\\n  except Exception as e:\\n    print(f\"An error occurred: {e}\")\\n\\n# Example usage\\nfilename = \\'employee_data.bin\\'\\nrecord_number = 2  # Update the 3rd record (0-based index)\\nnew_name = \\'Alice Smith\\'\\n\\nupdate_employee_name(filename, record_number, new_name)'},\n",
       " {'role': 'Assistant',\n",
       "  'content': \"Explanation:\\n\\n1. The `update_employee_name` function takes the filename, record number, and new name as arguments.\\n2. It defines the `record_size` based on the assumed structure of the employee data (4 bytes for ID and 20 bytes for the name).\\n3. It opens the file in read-write binary mode (`'rb+'`).\\n4. The `byte_offset` is calculated by multiplying the record number with the record size.\\n5. `file.seek()` moves the file pointer to the calculated byte offset.\\n6. Optionally, the existing ID is read using `file.read(4)` and converted to an integer.\\n7. The new name is encoded with the same fixed length as the original name and padded with spaces if necessary.\\n8. `file.write()` writes the encoded new name data at the current file pointer position, updating the name in the record.\\n9. The function prints a success message with the updated record information.\\n10. Error handling is included for file not found and other exceptions.\\n11. The example usage demonstrates how to call the function with specific parameters.\\n\\nThis approach allows you to efficiently update a specific record in the binary file without modifying the entire file contents. Remember to adjust the record_size based on your actual data structure and handle potential errors appropriately.\\n\\nFeel free to reach out if you require further clarification or assistance with anything else.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_turns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating output schema.....\n",
      "{'has_code': False, 'complete_code': False, 'can_be_tested': False, 'code': '', 'dependencies': [], 'language': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = conversation_turns[0]\n",
    "result = turn_classifier([HumanMessage(\"hello how are you?\")])\n",
    "print(result)\n",
    "all([result[\"has_code\"], result[\"complete_code\"], result[\"can_be_tested\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating output schema.....\n",
      "{'has_code': True, 'complete_code': False, 'can_be_tested': False, 'code': \"print('i am fine)\", 'dependencies': [], 'language': 'python3'}\n"
     ]
    }
   ],
   "source": [
    "result = turn_classifier([HumanMessage(\"print('i am fine)\")])\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
