{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.models import LLMModel\n",
    "from langchain_core.messages import (HumanMessage)\n",
    "from langchain.prompts import SystemMessagePromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple callable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in 2023, the President of Nigeria is Muhammadu Buhari. He has been in office since May 29, 2015, after winning the presidential election of that year. Buhari was re-elected for a second term in the 2019 presidential elections. However, political situations can change, so for the most current information, it would be best to check the latest news or official sources.\n",
      "--------------------------------\n",
      "As of my last update in early 2023, the President of Nigeria is Muhammadu Buhari. However, please note that Nigeria was due to hold presidential elections in February 2023. Depending on the current date and any developments since my last update, there might be a new president if the elections have taken place and a new president has been inaugurated. For the most accurate and current information, please check the latest news or official announcements.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = LLMModel(\n",
    "    provider=\"openai_api\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    output_schema=None, \n",
    "    )\n",
    "\n",
    "\n",
    "# YOU CAN EITHER PASS A LIST OF LANGCHAIN CORE MESSAGES OR A DICTIONARY WITH KEY `MESSAGES`\n",
    "response = model(\n",
    "    [HumanMessage(content=\"Who is the president of Nigeria\")]\n",
    "    )\n",
    "print(response)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "response = model(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Who is the president of Nigeria\")]\n",
    "    }\n",
    "    )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Output Schema and prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SETUP': 'WHY DID THE SCARECROW WIN AN AWARD?', 'PUNCHLINE': 'BECAUSE HE WAS OUTSTANDING IN HIS FIELD!'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke model\"\"\"\n",
    "    setup: str = Field(..., description=\"setup for the joke\")\n",
    "    punchline: str = Field(..., description=\"punchline for the joke\")\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"Given this topic={topic}, generate a joke.\"\n",
    "                ),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"Also, make your output all upper case LIKE THIS.\"\n",
    "                )\n",
    "               \n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "model1 = LLMModel(\n",
    "    provider=\"fireworks_api\",\n",
    "    model=\"llama-v3-70b-instruct\",\n",
    "    output_schema=Joke,\n",
    "    try_to_parse = True, # model will return JSON object based on the output schema\n",
    "    config = {\"retry\": 2, \"retry_with_history\": False}, #if model fails to output parsable response, it retries 2 time without providing failed response as feedback\n",
    "    prompt_template=prompt_template\n",
    "    )\n",
    "\n",
    "\n",
    "inputs = {\"topic\": \"dad jokes\"}\n",
    "response = model1(inputs)\n",
    "    \n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using as an Evaluator\n",
    "\n",
    "The Models.schemas module comes with some pre-defined pydantic schemas:\n",
    "1. **FeedbackISC**: This can be used as an output schema for evaluation to get `Issues`, `Score` and `Comments`\n",
    "2. **FeedbackBasic**: This can be used as an output schema to get a a dictionary with response (Default value when `try_to_parse` is set to true)\n",
    "3. **QualityAspect**: This is used to define the Evaluation Quality aspect with an `AspectorEvaluatorInputSchema` schema\n",
    "4. **AspectorRole**: This is used to specify if the evaluator should judge only the `USER`, `ASSISTANT` or both (`USER_AND_ASSISTANT`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'issues': [\"assistant's sentence is a bit long and could be broken up for better clarity.\"], 'score': 4, 'comment': \"The grammar and structure of both user and assistant responses are generally good, with proper use of punctuation and clear sentence structure. However, the assistant's response could be improved by breaking up a long sentence for better clarity.\"}\n",
      "--------------------------------\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from Models.schemas import AspectorEvaluatorInputSchema, FeedbackISC, FeedbackBasic,  QualityAspect, AspectorRole\n",
    "\n",
    "\n",
    "#TO TAKE ADVANTAGE OF THE SPECIAL EVALUATOR PROMPT, SET as_evaluator to True\n",
    "evaluator = LLMModel(\n",
    "    provider=\"fireworks_api\",\n",
    "    model=\"llama-v3-70b-instruct\",\n",
    "    output_schema=FeedbackISC, \n",
    "    input_schema=AspectorEvaluatorInputSchema, \n",
    "    name=\"aspect_evaluator\",\n",
    "    as_evaluator = True,\n",
    "    try_to_parse=True\n",
    ")\n",
    "\n",
    "#Conversation to be judged by the evaluator\n",
    "convo = [\n",
    "    \"user: Hello, are you doing today?\",\n",
    "    \"assistant: I'm doing well, thank you for asking! How can I assist you today?\",\n",
    "    \"user: I was hoping you could provide some feedback, on a short essay. I wrote. Would you be able to take a look and let me know your thoughts on the grammar and structure?\",\n",
    "    \"assistant: Absolutely, I'd be happy to review, your essay and provide feedback on the grammar and overall structure. Please go ahead and send over the essay whenever you're ready, and I'll take a look. Let me know if there are any specific areas you'd like me to focus on in addition to the grammar and structure.\"\n",
    "    ]\n",
    "\n",
    "\n",
    "#Define the aspect to be judge\n",
    "quality_aspect = QualityAspect(\n",
    "    name=\"grammar\",\n",
    "    instruction=\"The quality of the grammar including how well it is structured and punctuated\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set the evaluation task (model input)\n",
    "evaluation_task = AspectorEvaluatorInputSchema(\n",
    "    quality_aspect=quality_aspect,\n",
    "    role=AspectorRole.USER_AND_ASSISTANT,\n",
    "    conversation=convo,\n",
    "    metadata = {}\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Perform evaluation\n",
    "evaluation_result = evaluator(evaluation_task)\n",
    "print(evaluation_result)\n",
    "print(\"--------------------------------\")\n",
    "print(type(evaluation_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Extra Model configuration (Parameters and Model Kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"A three-legged dog. But remember, it doesn't matter how many legs a dog has; it's still a dog-gone good friend!\"}\n",
      "--------------------------------\n",
      "{'response': \"You might call it a 'bi-pawed' friend, but no matter the number of legs, it's still paws-itively lovable!\"}\n",
      "--------------------------------\n",
      "{'response': \"A one-legged dog? That's a 'uni-pawed' pal – still just as fetching as any other!\"}\n"
     ]
    }
   ],
   "source": [
    "model = LLMModel(\n",
    "    provider=\"openai_api\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    output_schema=FeedbackBasic,\n",
    "    prompt_template=ChatPromptTemplate.from_messages([(\"system\",\n",
    "                                         \"You are a funny virtual assistant\")]), #add extra personality configuration\n",
    "    try_to_parse = True, \n",
    "    config = {\"retry\": 2, \n",
    "              \"retry_with_history\": True,\n",
    "              \"params\": {'temperature':0.9}, # Extra model parameters goes here\n",
    "              #\"model_kwargs\": {}  # Extra kwargs can be added here\n",
    "              }\n",
    "    )\n",
    "\n",
    "\n",
    "messages=[HumanMessage(content=\"What do you call a dog with 3 legs?\"),]\n",
    "response = model(messages)\n",
    "print(response)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "messages=[HumanMessage(content=\"What about  a dog with 2 legs?\"),]\n",
    "response = model(messages)\n",
    "print(response)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "messages=[HumanMessage(content=\"1 leg?\"),]\n",
    "response = model(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAT HISTORY AND TOKEN COUNT\n",
    "1. use `model.chat_history`  to retrieve chat history without system prompt (or prompt template)\n",
    "2. use `model.get_chat_history()` to retrieve chat history with system prompt (or prompt template)\n",
    "3. use `model.chat_history_untouched` to retrieve chat history with system prompt and failed responses (failed parsed responses)\n",
    "4. use `model.get_total_tokens()` to retrieve  both token count and content used to retrieve the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " AIMessage(content='A dog with three legs can be lovingly referred to as a \"tripod\" or a \"tricycle,\" but no matter what you call them, they\\'re often just as capable and adorable as their four-legged pals. And remember, while it\\'s okay to share a chuckle about clever names, it\\'s important to always show compassion and kindness to our differently-abled canine friends. 🐾', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 30, 'total_tokens': 111}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7fbcc817-d991-4048-a1e2-3211fd5cc510-0'),\n",
       " HumanMessage(content='What about  a dog with 2 legs?'),\n",
       " AIMessage(content='A dog with two legs may not have a specific funny name, but I\\'ve heard some endearingly be called \"bipods.\" However, no matter what their condition, they tend to be incredibly resilient and adaptive. Some of these remarkable dogs even learn to walk upright or use special wheelchairs to get around. Always an inspiration, they show that with love and support, there are very few limits to what can be achieved. And remember, every dog deserves a good belly rub and a loving home, regardless of the number of legs they have! 🐶❤️', response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 129, 'total_tokens': 247}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-433afb1a-2c4e-41ff-a7db-e20adc5bff46-0'),\n",
       " HumanMessage(content='1 leg?'),\n",
       " AIMessage(content=\"A dog with only one leg would be quite rare and would likely need a great deal of special care and assistance for mobility, such as a custom wheelchair or a prosthetic limb. As for a humorous name, well, most people would probably prioritize empathy and support over coming up with a funny nickname in such a situation.\\n\\nIt's important to remember that while humor can be found in many aspects of life, the wellbeing and dignity of animals (and people) should always come first. For a dog with such unique challenges, the love and dedication of their human companions would be the most crucial thing to ensure they live a happy and fulfilling life.\", response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 258, 'total_tokens': 386}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2bf35701-d811-4abd-b426-577331ce777b-0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without system prompt\n",
    "model.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='\\nYou are a funny virtual assistant\\n'),\n",
       " HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " AIMessage(content='A dog with three legs can be lovingly referred to as a \"tripod\" or a \"tricycle,\" but no matter what you call them, they\\'re often just as capable and adorable as their four-legged pals. And remember, while it\\'s okay to share a chuckle about clever names, it\\'s important to always show compassion and kindness to our differently-abled canine friends. 🐾', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 30, 'total_tokens': 111}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7fbcc817-d991-4048-a1e2-3211fd5cc510-0'),\n",
       " HumanMessage(content='What about  a dog with 2 legs?'),\n",
       " AIMessage(content='A dog with two legs may not have a specific funny name, but I\\'ve heard some endearingly be called \"bipods.\" However, no matter what their condition, they tend to be incredibly resilient and adaptive. Some of these remarkable dogs even learn to walk upright or use special wheelchairs to get around. Always an inspiration, they show that with love and support, there are very few limits to what can be achieved. And remember, every dog deserves a good belly rub and a loving home, regardless of the number of legs they have! 🐶❤️', response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 129, 'total_tokens': 247}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-433afb1a-2c4e-41ff-a7db-e20adc5bff46-0'),\n",
       " HumanMessage(content='1 leg?'),\n",
       " AIMessage(content=\"A dog with only one leg would be quite rare and would likely need a great deal of special care and assistance for mobility, such as a custom wheelchair or a prosthetic limb. As for a humorous name, well, most people would probably prioritize empathy and support over coming up with a funny nickname in such a situation.\\n\\nIt's important to remember that while humor can be found in many aspects of life, the wellbeing and dignity of animals (and people) should always come first. For a dog with such unique challenges, the love and dedication of their human companions would be the most crucial thing to ensure they live a happy and fulfilling life.\", response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 258, 'total_tokens': 386}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2bf35701-d811-4abd-b426-577331ce777b-0')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with system prompt\n",
    "model.get_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " AIMessage(content='A dog with three legs can be lovingly referred to as a \"tripod\" or a \"tricycle,\" but no matter what you call them, they\\'re often just as capable and adorable as their four-legged pals. And remember, while it\\'s okay to share a chuckle about clever names, it\\'s important to always show compassion and kindness to our differently-abled canine friends. 🐾', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 30, 'total_tokens': 111}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7fbcc817-d991-4048-a1e2-3211fd5cc510-0'),\n",
       " HumanMessage(content='What about  a dog with 2 legs?'),\n",
       " AIMessage(content='A dog with two legs may not have a specific funny name, but I\\'ve heard some endearingly be called \"bipods.\" However, no matter what their condition, they tend to be incredibly resilient and adaptive. Some of these remarkable dogs even learn to walk upright or use special wheelchairs to get around. Always an inspiration, they show that with love and support, there are very few limits to what can be achieved. And remember, every dog deserves a good belly rub and a loving home, regardless of the number of legs they have! 🐶❤️', response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 129, 'total_tokens': 247}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-433afb1a-2c4e-41ff-a7db-e20adc5bff46-0'),\n",
       " HumanMessage(content='1 leg?'),\n",
       " AIMessage(content=\"A dog with only one leg would be quite rare and would likely need a great deal of special care and assistance for mobility, such as a custom wheelchair or a prosthetic limb. As for a humorous name, well, most people would probably prioritize empathy and support over coming up with a funny nickname in such a situation.\\n\\nIt's important to remember that while humor can be found in many aspects of life, the wellbeing and dignity of animals (and people) should always come first. For a dog with such unique challenges, the love and dedication of their human companions would be the most crucial thing to ensure they live a happy and fulfilling life.\", response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 258, 'total_tokens': 386}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2bf35701-d811-4abd-b426-577331ce777b-0')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with failed parses\n",
    "model.chat_history_untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: ...API token count\n"
     ]
    }
   ],
   "source": [
    "#Get Tokens\n",
    "tokens, tokens_string = model.get_total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 715, 'out': 105}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nYou are a funny virtual assistant\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"response\": {\"description\": \"The response string returned by the LLM\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"response\"]}\\n```What do you call a dog with 3 legs?',\n",
       " '\\nYou are a funny virtual assistant\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"response\": {\"description\": \"The response string returned by the LLM\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"response\"]}\\n```What do you call a dog with 3 legs?{\\n  \"response\": \"A three-legged dog. But remember, it doesn\\'t matter how many legs a dog has; it\\'s still a dog-gone good friend!\"\\n}What about  a dog with 2 legs?',\n",
       " '\\nYou are a funny virtual assistant\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"response\": {\"description\": \"The response string returned by the LLM\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"response\"]}\\n```What do you call a dog with 3 legs?{\\n  \"response\": \"A three-legged dog. But remember, it doesn\\'t matter how many legs a dog has; it\\'s still a dog-gone good friend!\"\\n}What about  a dog with 2 legs?{\\n  \"response\": \"You might call it a \\'bi-pawed\\' friend, but no matter the number of legs, it\\'s still paws-itively lovable!\"\\n}1 leg?']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_string[\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n  \"response\": \"A three-legged dog. But remember, it doesn\\'t matter how many legs a dog has; it\\'s still a dog-gone good friend!\"\\n}',\n",
       " '{\\n  \"response\": \"You might call it a \\'bi-pawed\\' friend, but no matter the number of legs, it\\'s still paws-itively lovable!\"\\n}',\n",
       " '{\\n  \"response\": \"A one-legged dog? That\\'s a \\'uni-pawed\\' pal – still just as fetching as any other!\"\\n}']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_string[\"out\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Turn off chat History\n",
    "\n",
    "This will save token cost since every new message is passed to the model without the chat history included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"A dog with three legs is often simply called a 'tripod' as a nickname. This term is used affectionately to describe a three-legged dog.\"}\n",
      "--------------------------------\n",
      "{'response': 'A dog with two legs would have significant challenges with mobility and would require special care and accommodations. Owners of such dogs often provide them with wheeled carts or harnesses to help them move around and live a more comfortable life.'}\n",
      "--------------------------------\n",
      "{'response': 'What was my first message?'}\n"
     ]
    }
   ],
   "source": [
    "model = LLMModel(\n",
    "    provider=\"openai_api\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    use_history = False,     \n",
    "    )\n",
    "\n",
    "\n",
    "messages=[HumanMessage(content=\"What do you call a dog with 3 legs?\"),]\n",
    "response = model(messages)\n",
    "print(response)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "messages=[HumanMessage(content=\"What about  a dog with 2 legs?\"),]\n",
    "response = model(messages)\n",
    "print(response)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "messages=[HumanMessage(content=\"What was my first message?\"),]\n",
    "response = model(messages)\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chat_history #You will get and empty history here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUDGE USE CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = {'status': 'OK',\n",
    " 'metadata': {'metadata': '# Metadata\\n\\n**Python Topics** - algorithms > by_topic > probability\\n\\n**Type** - query\\n\\n**Target Number of Turns (User + Assistant)** - 2\\n'},\n",
    " 'conversation': [{'cell_pos': 1,\n",
    "   'role': 'User',\n",
    "   'content': 'Could you show me a Python function to calculate the probability of rolling a sum of 8 with two six-sided dice?',\n",
    "   'type': 'markdown'},\n",
    "  {'cell_pos': 2,\n",
    "   'role': 'Assistant',\n",
    "   'content': 'Certainly! When you roll two six-sided dice, there are 36 possible outcomes (as there are 6 possible outcomes for each die). To determine the probability of obtaining a sum of 8, you must identify the favorable outcomes (those resulting in a sum of 8) and then divide this count by the total number of possible outcomes.\\n\\nHere is a python function for it:',\n",
    "   'type': 'markdown'},\n",
    "  {'cell_pos': 3,\n",
    "   'role': 'Assistant',\n",
    "   'content': 'def probability_of_rolling_sum_eight():\\n    favorable_outcomes = 0\\n    total_outcomes = 36 # There are 6 * 6 = 36 total outcomes\\n\\n    for dice_1 in range(1, 7):\\n        dice_2 = 8 - dice_1\\n\\n        # Check if the value is valid\\n        if 1 <= dice_2 <= 6:\\n            favorable_outcomes += 1\\n\\n    return favorable_outcomes / total_outcomes\\n\\n# Call the function and print the result\\nprobability_of_rolling_sum_eight = probability_of_rolling_sum_eight()\\n\\nprint(f\"The probability of rolling a sum of 8 with two six-sided dice is: {probability_of_rolling_sum_eight}\")',\n",
    "   'type': 'code'},\n",
    "  {'cell_pos': 4,\n",
    "   'role': 'Assistant',\n",
    "   'content': 'The time complexity of the `probability_of_rolling_sum_eight` function is O(N) since it undergoes a constant number of iterations (6 iterations, corresponding to each possible value of dice_1 ranging from 1 to 6).The loop entails basic arithmetic operations and conditional checks, all with constant time complexity.\\n\\nAs a result, the time complexity remains constant and is not influenced by the input size, irrespective of the number of sides on the dice. The function is specifically tailored for six-sided dice, ensuring a consistent and limited number of iterations.',\n",
    "   'type': 'markdown'},\n",
    "  {'cell_pos': 5,\n",
    "   'role': 'User',\n",
    "   'content': 'Could you kindly provide the result with precision up to four decimal places only?',\n",
    "   'type': 'markdown'},\n",
    "  {'cell_pos': 6,\n",
    "   'role': 'Assistant',\n",
    "   'content': \"Certainly! Here's the revised version of the function that will provide the outcome with accuracy up to four decimal places.\",\n",
    "   'type': 'markdown'},\n",
    "  {'cell_pos': 7,\n",
    "   'role': 'Assistant',\n",
    "   'content': 'def probability_of_rolling_sum_eight():\\n    favorable_outcomes = 0\\n    total_outcomes = 36 # There are 6 * 6 = 36 total outcomes\\n\\n    for die1 in range(1, 7):\\n        die2 = 8 - die1\\n\\n        # Check if the value is valid\\n        if 1 <= die2 <= 6:\\n            favorable_outcomes += 1\\n\\n    return favorable_outcomes / total_outcomes\\n\\n# Call the function and print the result\\nprobability_of_rolling_sum_eight = probability_of_rolling_sum_eight()\\n\\nprint(f\"The probability of rolling a sum of 8 with two six-sided dice is: {probability_of_rolling_sum_eight: .4f}\")',\n",
    "   'type': 'code'}]}\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"Name: AI Assistant Perfector.\n",
    "Profile: You are an expert in perfecting AI Assistants' response content based on the user's expertise level.\"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "Given the following conversation between Human User and AI Assistant, find issues following the rules described below and rate the total conversation.\n",
    "Single significant instance of deviation from the rules - score 1 or 2. More issues score<2. No issues=5.\n",
    "\n",
    "Qualities we care about. Focus on them and only find issues that are directly related to them:\n",
    "```\n",
    "You must assume the user just started to learn about the question that is asked, so the \n",
    "reply should cover all the points that the user might be new to, and assume the \n",
    "user has basic knowledge about the prerequisites. \n",
    "\n",
    "This helps us keep the explanation clean, and makes it useful to the user rather \n",
    "than throwing all information about the topic to the user.\n",
    "\n",
    "It is important to identify the query intent to gauge the user knowledge level as well as \n",
    "the code complexity to provide the most useful explanation.\n",
    "```\n",
    "\n",
    "The task:\n",
    "```\n",
    "Please, detect all mismatches between user's expertise level shown and the replies of the Assistant.\n",
    "If User expertise level is unknown - asumme they are a beginner in that question.\n",
    "Mismatches might include but not limited to:\n",
    "    - too much explanation for an expert\n",
    "    - too little explanation for a beginner\n",
    "    - Assistant assumes the user is not the beginner in the question asked be it an algo or a technology or something else.\n",
    "\n",
    "Assume basic knowledge of Python programming by the user and so no need to explain basic things unless asked to.\n",
    "For example, if the question is about an algorithm in python, assume understnding of Python but a beginner level in algorithms UNLESS USER SHOWS OR STATES A HIGHER OR LOWER LEVEL OF EXPERTISE.\n",
    "\n",
    "If no issues found, do not create any.\n",
    "Correctness or accuracy is not your concern and will be handled by other evaluators. Focus only on the serving user's level of expertise in the most helpful manner.\n",
    "```\n",
    "\n",
    "Conversation:\n",
    "CONVERSATION_START\n",
    "{conversation}\n",
    "CONVERSATION_END\n",
    "\n",
    "Now, proceed to completing your task of finding issues and scoring the conversation.\n",
    "\"\"\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "class UserExpertise(BaseModel):\n",
    "    \"\"\"User expertise level in a inquiry topic.\"\"\"\n",
    "\n",
    "    inquiry_topic: str = Field(..., description=\"The topic of the user's inquiry.\")\n",
    "    level: str = Field(\n",
    "        ...,\n",
    "        description=\"The user's expertise level in the inquiry topic. Even if assumed. Be concise, 1 sentence max.\",\n",
    "    )\n",
    "    \n",
    "class Intent(BaseModel):\n",
    "    \"\"\"User intent.\"\"\"\n",
    "\n",
    "    cell_pos: int\n",
    "    intent: str = Field(\n",
    "        ...,\n",
    "        description=\"User intent, concise, single sentence per user reply. Avoid Assistant intent\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.schemas import NotebookWiseFeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_intents': [{'cell_pos': 1,\n",
       "   'intent': 'User asks for a Python function to calculate the probability of rolling a sum of 8 with two six-sided dice.'},\n",
       "  {'cell_pos': 5,\n",
       "   'intent': 'User requests the result to be shown with precision up to four decimal places.'}],\n",
       " 'user_expertise_level': {'inquiry_topic': 'Probability algorithms in Python',\n",
       "  'level': 'Beginner'},\n",
       " 'scratchpad': 'The user starts by inquiring about a specific Python function related to probability, indicating they are a beginner in this specific area of probability algorithms. The assistant provides a detailed explanation along with a Python code snippet, which is appropriate for a beginner. However, the explanation about time complexity in the fourth cell might not be necessary at this stage for a beginner focusing primarily on understanding basic probability calculation, not performance optimization. This could possibly confuse or overwhelm a beginner.',\n",
       " 'issues': [{'type': 'Excessive explanation for a beginner',\n",
       "   'reason': 'The assistant explains the time complexity of the Python function, which may not be necessary for a beginner primarily interested in the basic probability calculation.',\n",
       "   'cell_positions': [4],\n",
       "   'fix': 'Simplify the response by focusing on the probability calculation and omit the explanation of time complexity unless further queried about performance aspects.'}],\n",
       " 'score': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = LLMModel(\n",
    "    provider=\"openai_api\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    output_schema=NotebookWiseFeedback,\n",
    "    name=\"aspect_evaluator\",\n",
    "    prompt_template=chat_template,\n",
    "    try_to_parse=True\n",
    ")\n",
    "\n",
    "\n",
    "# Perform evaluation\n",
    "evaluation_result = evaluator({\n",
    "    \"conversation\": conversation\n",
    "})\n",
    "\n",
    "evaluation_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
