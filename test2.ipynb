{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Models.models import LLMModel\n",
    "from langchain_core.messages import (HumanMessage, SystemMessage, AIMessage)\n",
    "import json\n",
    "from Models.schemas import AspectorEvaluatorInputSchema, FeedbackISC, FeedbackBasic,  QualityAspect, AspectorRole\n",
    "\n",
    "\n",
    "model1 = LLMModel(\n",
    "    provider=\"anthropic_api\",\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    output_schema=FeedbackBasic,\n",
    "    #chat_history=[]\n",
    "    try_to_parse=True,\n",
    "    #tools\n",
    "    config = {\"retry\": 2, \"retry_with_history\": False}\n",
    "    )\n",
    "\n",
    "# from Models.models import CustomJSONParser\n",
    "# CustomJSONParser('''Here is a possible humorous response in the requested JSON format:\\n\\n{\\n  \"response\": \"A tripod.\"\\n}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False , 2\n"
     ]
    }
   ],
   "source": [
    "print(model1.retry_with_history, \",\", model1.retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: First Message\n",
      "DEBUG:  content='Here is a possible response, formatted as the specified JSON schema:\\n\\n{\\n  \"response\": \"There are a few humorous names you could give to a three-legged dog:\\n\\nTripod - since the dog would stand on three legs like a tripod. \\nThreego - a play on the name Fido.\\nLucky - an ironic name since the dog is missing a leg.\\nSkippy - because the dog would likely skip or hop when walking or running.\\n\\nHowever, more than focusing on a cute name, a dog with three legs should be treated with extra love, care and support to help it adapt and thrive despite its disability. The dog\\'s name should reflect its personality more than its physical condition.\"\\n}' response_metadata={'id': 'msg_01UB7EWiQC42zYuCqvNNNYQT', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 189, 'output_tokens': 161}} id='run-8f3db7bc-96bb-44f5-b021-2ab9381f86c2-0'\n",
      "retrying... retry remaining  1\n",
      "DEBUG:  content='Here is a possible humorous response to the joke prompt \"What do you call a dog with 3 legs?\":\\n\\n{\\n  \"response\": \"A tripod!\"\\n}' response_metadata={'id': 'msg_01Xv5dD7L3xEkcLhXVgYAxs3', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 201, 'output_tokens': 42}} id='run-d7a4db50-b869-47f8-abcd-cfc70edeb759-0'\n",
      "{'response': 'A tripod!', 'other_content': 'Here is a possible humorous response to the joke prompt \"What do you call a dog with 3 legs?\":\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "messages=[HumanMessage(content=\"What do you call a dog with 3 legs?\"),]\n",
    "response = model1(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " AIMessage(content='Here is a possible humorous response to the joke prompt \"What do you call a dog with 3 legs?\":\\n\\n{\\n  \"response\": \"A tripod!\"\\n}', response_metadata={'id': 'msg_01Xv5dD7L3xEkcLhXVgYAxs3', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 201, 'output_tokens': 42}}, id='run-d7a4db50-b869-47f8-abcd-cfc70edeb759-0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a dog with 3 legs?\n",
      "Here is a possible response, formatted as the specified JSON schema:\n",
      "\n",
      "{\n",
      "  \"response\": \"There are a few humorous names you could give to a three-legged dog:\n",
      "\n",
      "Tripod - since the dog would stand on three legs like a tripod. \n",
      "Threego - a play on the name Fido.\n",
      "Lucky - an ironic name since the dog is missing a leg.\n",
      "Skippy - because the dog would likely skip or hop when walking or running.\n",
      "\n",
      "However, more than focusing on a cute name, a dog with three legs should be treated with extra love, care and support to help it adapt and thrive despite its disability. The dog's name should reflect its personality more than its physical condition.\"\n",
      "}\n",
      "What do you call a dog with 3 legs?\n",
      "Here is a possible humorous response to the joke prompt \"What do you call a dog with 3 legs?\":\n",
      "\n",
      "{\n",
      "  \"response\": \"A tripod!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i in model1.chat_history_untouched:\n",
    "    print (i.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: ...API token count\n",
      "{'in': 647, 'out': 243}\n"
     ]
    }
   ],
   "source": [
    "a,b = model1.get_total_tokens()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:  content='Here is a possible response to continue the joke series \"What do you call a dog with 2 legs?\":\\n\\n{\\n  \"response\": \"Lean!\"\\n}' response_metadata={'id': 'msg_01138nZJx73QL5yz9CiZUJhP', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 257, 'output_tokens': 40}} id='run-ffa7361e-ce9a-4732-a421-88eb64090c1e-0'\n",
      "{'response': 'Lean!', 'other_content': 'Here is a possible response to continue the joke series \"What do you call a dog with 2 legs?\":\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "messages=[HumanMessage(content=\"What about  a dog with 2 legs?\"),]\n",
    "response = model1(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:  content='{\\n  \"response\": \"Eileen!\"\\n}' response_metadata={'id': 'msg_01HLAfTT2wEMyKpNhp78wfRf', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 265, 'output_tokens': 16}} id='run-3cd205af-0345-4707-8b2f-83fd23456d66-0'\n",
      "{'response': 'Eileen!'}\n"
     ]
    }
   ],
   "source": [
    "messages=[HumanMessage(content=\"1 leg?\"),]\n",
    "response = model1(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:  content='{\\n  \"response\": \"Matt!\"\\n}' response_metadata={'id': 'msg_018JckBhGMjXUTUmhsTNtf29', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 289, 'output_tokens': 14}} id='run-7a42a729-0a4b-47df-a74a-a134af064fb8-0'\n",
      "{'response': 'Matt!'}\n"
     ]
    }
   ],
   "source": [
    "messages=[HumanMessage(content=\"no legs atall?\"),]\n",
    "response = model1(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"response\": {\"description\": \"The response string returned by the LLM\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"response\"]}\\n```'),\n",
       " HumanMessage(content='What do you call a dog with 3 legs?'),\n",
       " AIMessage(content='Here is my attempt to generate a witty response in the specified JSON format:\\n\\n{\\n  \"response\": \"A tripawed!\"\\n}', response_metadata={'id': 'msg_019Qc5YpKRNWazjPWpHFFADC', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 189, 'output_tokens': 33}}, id='run-3dcdad60-29ff-42e3-b8c5-2638d217ad07-0'),\n",
       " HumanMessage(content='What about  a dog with 2 legs?'),\n",
       " AIMessage(content='{\\n  \"response\": \"A walkie, not a talkie!\"\\n}', response_metadata={'id': 'msg_019HChbuFQxuFJ6wZ9Wqcpgz', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 236, 'output_tokens': 21}}, id='run-67cc5d81-bfca-4e25-ae5a-5eae862f4e16-0'),\n",
       " HumanMessage(content='1 leg?'),\n",
       " AIMessage(content='{\\n  \"response\": \"Eileen!\"\\n}', response_metadata={'id': 'msg_01HLAfTT2wEMyKpNhp78wfRf', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 265, 'output_tokens': 16}}, id='run-3cd205af-0345-4707-8b2f-83fd23456d66-0'),\n",
       " HumanMessage(content='no legs atall?'),\n",
       " AIMessage(content='{\\n  \"response\": \"Matt!\"\\n}', response_metadata={'id': 'msg_018JckBhGMjXUTUmhsTNtf29', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 289, 'output_tokens': 14}}, id='run-7a42a729-0a4b-47df-a74a-a134af064fb8-0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: ...API token count\n"
     ]
    }
   ],
   "source": [
    "count, concat = model1.get_total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"response\": {\"description\": \"The response string returned by the LLM\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"response\"]}\n",
      "```What do you call a dog with 3 legs?Here is my attempt to generate a witty response in the specified JSON format:\n",
      "\n",
      "{\n",
      "  \"response\": \"A tripawed!\"\n",
      "}What about  a dog with 2 legs?{\n",
      "  \"response\": \"A walkie, not a talkie!\"\n",
      "}1 leg?{\n",
      "  \"response\": \"Eileen!\"\n",
      "}no legs atall?\n"
     ]
    }
   ],
   "source": [
    "print(concat[\"in\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday 9th of May 2024 Updates \n",
    "1. Prompt Token (output and input) - (This requires adding up all the tokens in each message in the history) - FIXED\n",
    "\n",
    "### TO DO\n",
    "1. limited retry feature (pass this with the config parameter as retry (0-5), default will be 3)\n",
    "2. validate output schema when try_to_parse is True (and retry when fails, even if its json)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
