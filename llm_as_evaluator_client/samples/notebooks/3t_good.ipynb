{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7f2a006a",
      "metadata": {
        "id": "7f2a006a"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "**Python Topics** - ml_principles > knn_classification\n",
        "\n",
        "**Type** - modification\n",
        "\n",
        "**Target Number of Turns (User + Assistant)** - 2+\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c6b9e5",
      "metadata": {
        "id": "75c6b9e5"
      },
      "source": [
        "# Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18eea314",
      "metadata": {
        "id": "18eea314"
      },
      "source": [
        "**User**\n",
        "\n",
        "I need to perform a grid search to find the best number of neighbors for my KNN classifier. Can you show me how to integrate GridSearchCV for this purpose? Here's my current setup: from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Certainly! You can use `GridSearchCV` from the `sklearn.model_selection` module to perform a grid search and find the best hyperparameters for your KNN classifier. Here's an example of how to integrate GridSearchCV into your setup -\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11]}  # Adjust the list of values as needed\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Number of Neighbors:\", grid_search.best_params_['n_neighbors'])\n"
      ],
      "metadata": {
        "id": "YveUb0V5TiMa"
      },
      "id": "YveUb0V5TiMa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User**\n",
        "\n",
        "Can you show this on iris dataset?"
      ],
      "metadata": {
        "id": "TV6dW_65UIR8"
      },
      "id": "TV6dW_65UIR8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Certainly! Here's an example of how to perform a grid search for the best number of neighbors on the Iris dataset using GridSearchCV with a KNeighborsClassifier -"
      ],
      "metadata": {
        "id": "oBsYg0BdUP7P"
      },
      "id": "oBsYg0BdUP7P"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistant\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
        "print(\"Best Number of Neighbors:\", best_n_neighbors)\n",
        "\n",
        "# Access the best model (fitted with the best hyperparameters)\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaM8m7-yUUzB",
        "outputId": "67a1c79b-1e8c-4969-b260-8e0df767280b"
      },
      "id": "IaM8m7-yUUzB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Number of Neighbors: 3\n",
            "Test Accuracy with Best Model: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User**\n",
        "\n",
        "What other hyperparameters can I consider while tuning a KNN Classifier?"
      ],
      "metadata": {
        "id": "4KPdGcGcVhgV"
      },
      "id": "4KPdGcGcVhgV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assistant**\n",
        "\n",
        "Based on the official sklearn documentation, here are some key hyperparameters for the `KNeighborsClassifier` -\n",
        "\n",
        "1. `weights`: Specifies the weight assigned to neighbors when making predictions (`uniform` for equal weight, `distance` for inverse distance weighting).\n",
        "2. `p`: Defines the power parameter for the Minkowski distance metric (1 for Manhattan distance, 2 for Euclidean distance).\n",
        "3. `algorithm`: Algorithm for computing nearest neighbors ('auto', 'ball_tree', 'kd_tree', 'brute').\n",
        "4. `leaf_size`: Controls the size of leaf nodes in tree-based algorithms.\n",
        "5. `metric`: Specifies the distance metric used for the tree data structure.\n",
        "6. `n_jobs`: Determines the number of parallel jobs for neighbor search (-1 uses all available CPU cores).\n",
        "7. `outlier_label`: Assigns a label to outlier samples.\n",
        "\n",
        "Tuning these hyperparameters can optimize the performance of the KNN classifier based on the characteristics of your dataset and problem requirements.\n"
      ],
      "metadata": {
        "id": "7mkx6Y5FVtim"
      },
      "id": "7mkx6Y5FVtim"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}