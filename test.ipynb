{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.models import LLMModel\n",
    "from langchain_core.messages import (HumanMessage)\n",
    "import json\n",
    "from Models.schemas import AspectorEvaluatorInputSchema, FeedbackISC, FeedbackBasic,  QualityAspect, AspectorRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LLMModel(\n",
    "    provider=\"openai_api\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    output_schema=FeedbackBasic,\n",
    "    chat_history=[],\n",
    "    use_history= True,\n",
    "    )\n",
    "\n",
    "\n",
    "model2 = LLMModel(\n",
    "    provider=\"fireworks_api\",\n",
    "    model=\"llama-v3-70b-instruct\",\n",
    "    output_schema=FeedbackBasic,\n",
    "    chat_history=[],\n",
    "    use_history= True,\n",
    "    )\n",
    "\n",
    "\n",
    "model3 = LLMModel(\n",
    "    provider=\"anthropic_api\",\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    output_schema=FeedbackBasic,\n",
    "    chat_history=[],\n",
    "    use_history= True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'en haut'}\n",
      "--------------------------------\n",
      "{'response': 'How do you say up in french'}\n",
      "--------------------------------\n",
      "content='How do you say up in french '\n",
      "content='{\\n    \"response\": \"en haut\"\\n}' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 175, 'total_tokens': 185}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-71ff7ff2-a0b7-4ec1-9f8f-d33dc9ff869e-0'\n",
      "content='What was my first message.'\n",
      "content='{\\n    \"response\": \"How do you say up in french\"\\n}' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 199, 'total_tokens': 214}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a49cbe56-a630-43b5-8ccd-6589e2d9431e-0'\n",
      "--------------------------------\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "this_model = model1\n",
    "\n",
    "messages=[HumanMessage(content=\"How do you say up in french \"),]\n",
    "response = this_model(messages)\n",
    "print(json.loads(response.content))\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "messages=[HumanMessage(content=\"What was my first message.\"),]\n",
    "response = this_model(messages)\n",
    "print(json.loads(response.content))\n",
    "\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "for message in this_model.chat_history:\n",
    "    print(message)\n",
    "   \n",
    "    \n",
    "print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "tokens, all_message = this_model.get_total_tokens()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM AS EVALUATOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 3\n",
      "issues: [\"Missing word in user's first message\", \"Incorrect comma placement in assistant's second message\", \"Run-on sentence in user's second message\"]\n",
      "comment: The grammar in this conversation has a few issues. The user's messages are missing some words and have run-on sentences. The assistant's message has an incorrectly placed comma. However, the messages are still understandable overall. Some proofreading and editing would help improve the grammatical quality.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Example usage of LLMasEvaluator\n",
    "evaluator = LLMModel(\n",
    "    provider=\"anthropic_api\",\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    output_schema=FeedbackISC,\n",
    "    input_schema=AspectorEvaluatorInputSchema,\n",
    "    name=\"aspect_evaluator\",\n",
    "    chat_history=[],\n",
    "    use_history=False,\n",
    "    as_evaluator = True\n",
    ")\n",
    "\n",
    "convo = [\n",
    "    \"user: Hello, are you doing today?\",\n",
    "    \"assistant: I'm doing well, thank you for asking! How can I assist you today?\",\n",
    "    \"user: I was hoping you could provide some feedback, on a short essay. I wrote. Would you be able to take a look and let me know your thoughts on the grammar and structure?\",\n",
    "    \"assistant: Absolutely, I'd be happy to review, your essay and provide feedback on the grammar and overall structure. Please go ahead and send over the essay whenever you're ready, and I'll take a look. Let me know if there are any specific areas you'd like me to focus on in addition to the grammar and structure.\"\n",
    "    ]\n",
    "\n",
    "\n",
    "quality_aspect = QualityAspect(\n",
    "    name=\"grammar\",\n",
    "    instruction=\"The quality of the grammar including how well it is structured and punctuated\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create an instance of AspectorEvaluatorInputSchema\n",
    "evaluation_task = AspectorEvaluatorInputSchema(\n",
    "    quality_aspect=quality_aspect,\n",
    "    role=AspectorRole.USER_AND_ASSISTANT,\n",
    "    conversation=convo,\n",
    "    metadata = {}\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Perform evaluation\n",
    "evaluation_result = json.loads(evaluator(evaluation_task).content)\n",
    "\n",
    "print(f\"score: {evaluation_result[\"score\"]}\")\n",
    "print(f\"issues: {evaluation_result[\"issues\"]}\")\n",
    "print(f\"comment: {evaluation_result[\"comment\"]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token,system_message = evaluator.get_total_tokens()\n",
    "print(b[0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
